# Multi-Agent Maze Escape Simulation ğŸ¤–ğŸ”

A comprehensive Multi-Agent System (MAS) demonstration simulating cooperative robots navigating an underground maze. This project showcases key MAS principles including communication, coordination, negotiation, and emergent behavior.

## ğŸ¯ Project Overview

**Objective**: Simulate a team of cooperative robots navigating an underground maze to reach an exit while avoiding dead ends and optimizing the path collectively.

### Key Features

- âœ… **Communication**: Agents share information about dead ends and discovered paths via a shared blackboard
- âœ… **Coordination**: Dynamic task allocation to avoid redundant exploration
- âœ… **Negotiation**: Conflict resolution when multiple agents target the same path
- âœ… **Emergent Behavior**: Collective optimization through agent interaction
- âœ… **Real-time Visualization**: Pygame-based visual representation
- âœ… **Performance Metrics**: Compare single vs multi-agent efficiency

## ğŸ—ï¸ Architecture

```
maze_escape_mas/
â”œâ”€â”€ environment/      # Maze generation and representation
â”œâ”€â”€ agents/          # Robot agent implementation
â”œâ”€â”€ coordination/    # Blackboard and negotiation mechanisms
â”œâ”€â”€ simulation/      # Simulation logic and metrics
â”œâ”€â”€ visualization/   # Pygame rendering
â””â”€â”€ utils/          # Helper functions
```

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- pip (Python package manager)

## ğŸš€ Installation

### 1. Clone or Create the Project

```bash
# Create the folder structure
mkdir -p maze_escape_mas/{environment,agents,coordination,simulation,visualization,utils}
cd maze_escape_mas

# Create __init__.py files
touch environment/__init__.py
touch agents/__init__.py
touch coordination/__init__.py
touch simulation/__init__.py
touch visualization/__init__.py
touch utils/__init__.py
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

Or manually install:
```bash
pip install pygame numpy matplotlib
```

### 3. Verify Installation

```bash
python -c "import pygame, numpy, matplotlib; print('All dependencies installed!')"
```

## ğŸ® Usage

### Visual Mode (Default)

Run the simulation with real-time pygame visualization:

```bash
python main.py
```

**Controls:**
- `ESC` or Close Window: Exit simulation
- `R`: Reset simulation
- `SPACE`: Pause/Unpause (optional)

### Benchmark Mode

Compare performance across different agent counts:

```bash
# Test with default agent counts [1, 2, 3, 5, 7]
python main.py --mode benchmark

# Test specific agent counts
python main.py --mode benchmark --agents 1 3 5 10

# Run more trials for accuracy
python main.py --mode benchmark --agents 1 5 10 --trials 10

# Disable plotting
python main.py --mode benchmark --no-plot
```

## âš™ï¸ Configuration

Edit `config.py` to customize simulation parameters:

```python
# Maze Configuration
MAZE_WIDTH = 20          # Maze width
MAZE_HEIGHT = 20         # Maze height
WALL_DENSITY = 0.3       # Wall probability (0.0-1.0)

# Agent Configuration
NUM_AGENTS = 5           # Number of robot agents
AGENT_ENERGY = 100       # Starting energy per agent
AGENT_VISION_RANGE = 2   # Vision radius
COMMUNICATION_RANGE = 5  # Communication radius

# Simulation
MAX_STEPS = 1000         # Maximum simulation steps
SIMULATION_SPEED = 10    # Steps per second
```

## ğŸ§  Multi-Agent System Features

### 1. Communication
Agents communicate through a **shared blackboard** that stores:
- Explored cells
- Known dead ends
- Discovered paths
- Agent positions and targets

### 2. Coordination
- **Dynamic Task Allocation**: Agents negotiate to explore different branches
- **Redundancy Avoidance**: Shared knowledge prevents duplicate exploration
- **Resource Management**: Energy tracking and path optimization

### 3. Negotiation
When conflicts occur (multiple agents targeting the same position):
- Priority based on **distance** and **energy levels**
- Fair resource allocation
- Dynamic reassignment

### 4. Emergent Behavior
- Collective path optimization
- Faster solution discovery through parallel exploration
- Adaptive strategy based on shared knowledge

## ğŸ“Š Performance Metrics

The benchmark mode analyzes:
- **Steps to Completion**: Average number of steps to find exit
- **Exploration Coverage**: Percentage of maze explored
- **Success Rate**: Completion rate across trials
- **Computation Time**: Real-world execution time

### Sample Output:
```
============================================================
PERFORMANCE SUMMARY
============================================================

1 Agent(s):
  Average Steps:     487.2
  Average Explored:  156.4
  Success Rate:      100.0%
  Average Duration:  0.234s

5 Agent(s):
  Average Steps:     142.8
  Average Explored:  201.6
  Success Rate:      100.0%
  Average Duration:  0.198s

OPTIMAL CONFIGURATIONS:
  Fewest Steps:       5 agents (142.8 steps)
  Fastest Execution:  5 agents (0.198s)
============================================================
```

## ğŸ¨ Visualization Legend

| Color | Meaning |
|-------|---------|
| Green | Start position |
| Red | Exit position |
| Light Blue | Explored cells |
| Gray | Dead ends |
| White | Unexplored paths |
| Dark Gray | Walls |
| Colored Circles | Robot agents |

## ğŸ”¬ Academic Relevance

This project demonstrates essential MAS concepts:

1. **Agent Architecture**: Reactive agents with memory and local perception
2. **Communication Protocols**: Blackboard pattern for shared knowledge
3. **Coordination Mechanisms**: Distributed task allocation
4. **Negotiation Strategies**: Priority-based conflict resolution
5. **Emergent Intelligence**: System-level optimization from individual behaviors

## ğŸ“ˆ Expected Outcomes

- **Single Agent**: Slower but thorough exploration
- **Multiple Agents**: 
  - Faster exit discovery (2-3x improvement)
  - Better coverage through parallel exploration
  - Efficient dead-end identification
  - Demonstrates synergy through cooperation

## ğŸ› ï¸ Extending the Project

### Add New Agent Types
Edit `agents/robot_agent.py` to create specialized agents:
```python
class ScoutAgent(RobotAgent):
    """Fast agent with extended vision"""
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.vision_range = 4  # Extended vision
```

### Implement New Negotiation Strategies
Modify `coordination/negotiation.py`:
```python
@staticmethod
def auction_based_allocation(agents, targets):
    """Auction-based task allocation"""
    # Your implementation
```

### Add Obstacles or Resources
Extend `environment/maze.py`:
```python
class Maze:
    def add_dynamic_obstacles(self):
        """Add moving obstacles"""
        # Your implementation
```

## ğŸ“ Assignment Deliverables

This project is suitable for demonstrating:

1. âœ… Multi-agent communication
2. âœ… Coordination and cooperation
3. âœ… Negotiation protocols
4. âœ… Emergent behavior
5. âœ… Performance analysis
6. âœ… Scalability testing
7. âœ… Visual demonstration

## ğŸ› Troubleshooting

### Pygame Window Not Appearing
```bash
# Install pygame properly
pip uninstall pygame
pip install pygame==2.5.2
```

### Matplotlib Errors
```bash
# Install matplotlib backend
pip install matplotlib pillow
```

### Permission Errors
```bash
# Use virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

## ğŸ“š References

- Wooldridge, M. (2009). An Introduction to MultiAgent Systems
- Russell, S., & Norvig, P. (2020). Artificial Intelligence: A Modern Approach
- Ferber, J. (1999). Multi-Agent Systems: An Introduction to Distributed Artificial Intelligence

## ğŸ“„ License

This project is created for educational purposes.

## ğŸ‘¥ Contributing

Feel free to extend this project with:
- New agent behaviors
- Advanced pathfinding algorithms
- Different maze generation techniques
- Additional visualization features
- More sophisticated negotiation protocols

## ğŸ“§ Contact

For questions or issues, please create an issue in the repository or contact the maintainer.

---

**Happy Simulating! ğŸ¤–âœ¨**